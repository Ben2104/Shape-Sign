{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, LSTM, BatchNormalization, Dropout, InputLayer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\syngu\\OneDrive\\Documents\\GitHub\\HandGestureWithLSTM\\models\\data_main\\concated1.csv\"\n",
    ")\n",
    "window = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "thirsty           7448\n",
       "name              7159\n",
       "can               6984\n",
       "morning           6731\n",
       "help              6716\n",
       "eat               6706\n",
       "you               6560\n",
       "good              6132\n",
       "please            6083\n",
       "ILY2              5015\n",
       "no                4882\n",
       "I                 4714\n",
       "sorry             4630\n",
       "hungry            4109\n",
       "drink             3982\n",
       "you're welcome    3425\n",
       "thanks            3031\n",
       "my                2557\n",
       "Yes               2479\n",
       "yes               2200\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"label\"].unique().tolist()\n",
    "for label in labels:\n",
    "    sample_size = len(df.loc[df[\"label\"] == label]) //window *window\n",
    "    df.loc[df[\"label\"] == label] = df.loc[df[\"label\"] == label].head(\n",
    "        sample_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "X_sequence = []\n",
    "y_sequence = []\n",
    "for label in df[\"label\"].unique().tolist():\n",
    "    temp_df = df.loc[df[\"label\"]==label]\n",
    "    temp_X = temp_df.drop(columns=[\"label\"])\n",
    "    for i in range(len(temp_df)-window):\n",
    "        X_sequence.append(temp_X[i:i+window])\n",
    "        label = temp_df['label'].iloc[i+window]\n",
    "        y_sequence.append(label)\n",
    "\n",
    "\n",
    "X = np.array(X_sequence)\n",
    "y = np.array(y_sequence)\n",
    "\n",
    "y = encoder.fit_transform(y)\n",
    "y = to_categorical(y,len(df[\"label\"].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((89856, 60, 63), (89856, 20), (9984, 60, 63), (9984, 20))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['I', 'ILY2', 'Yes', 'can', 'drink', 'eat', 'good', 'help',\n",
       "       'hungry', 'morning', 'my', 'name', 'no', 'please', 'sorry',\n",
       "       'thanks', 'thirsty', 'yes', 'you', \"you're welcome\"], dtype='<U14')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        # InputLayer((30,63)),\n",
    "        InputLayer((60, 63)),\n",
    "        LSTM(128, return_sequences=True),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32,activation='relu'),\n",
    "        Dense(y.shape[1], activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=Adam(0.001)\n",
    ")\n",
    "# model = tf.keras.models.load_model(\n",
    "#     r\"C:\\Users\\syngu\\OneDrive\\Documents\\GitHub\\HandGestureWithLSTM\\models\\test_model_LSTM1.keras\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 218ms/step - accuracy: 0.2195 - loss: 2.4579 - val_accuracy: 0.5740 - val_loss: 1.1856\n",
      "Epoch 2/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 214ms/step - accuracy: 0.7309 - loss: 0.7790 - val_accuracy: 0.9021 - val_loss: 0.2630\n",
      "Epoch 3/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 227ms/step - accuracy: 0.7627 - loss: 0.7881 - val_accuracy: 0.9055 - val_loss: 0.3054\n",
      "Epoch 4/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 223ms/step - accuracy: 0.9136 - loss: 0.2543 - val_accuracy: 0.9644 - val_loss: 0.1277\n",
      "Epoch 5/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 229ms/step - accuracy: 0.9567 - loss: 0.1357 - val_accuracy: 0.9755 - val_loss: 0.0847\n",
      "Epoch 6/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 222ms/step - accuracy: 0.9698 - loss: 0.0968 - val_accuracy: 0.9822 - val_loss: 0.0455\n",
      "Epoch 7/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 221ms/step - accuracy: 0.9776 - loss: 0.0720 - val_accuracy: 0.9766 - val_loss: 0.0687\n",
      "Epoch 8/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 221ms/step - accuracy: 0.9448 - loss: 0.1756 - val_accuracy: 0.9277 - val_loss: 0.1922\n",
      "Epoch 9/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 223ms/step - accuracy: 0.9641 - loss: 0.1178 - val_accuracy: 0.9978 - val_loss: 0.0184\n",
      "Epoch 10/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 220ms/step - accuracy: 0.9941 - loss: 0.0204 - val_accuracy: 0.9933 - val_loss: 0.0139\n",
      "Epoch 11/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 224ms/step - accuracy: 0.9915 - loss: 0.0306 - val_accuracy: 0.9744 - val_loss: 0.1057\n",
      "Epoch 12/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 226ms/step - accuracy: 0.9842 - loss: 0.0542 - val_accuracy: 0.9978 - val_loss: 0.0118\n",
      "Epoch 13/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 228ms/step - accuracy: 0.9842 - loss: 0.0522 - val_accuracy: 0.9967 - val_loss: 0.0153\n",
      "Epoch 14/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 225ms/step - accuracy: 0.9950 - loss: 0.0173 - val_accuracy: 0.9956 - val_loss: 0.0173\n",
      "Epoch 15/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 225ms/step - accuracy: 0.9910 - loss: 0.0295 - val_accuracy: 1.0000 - val_loss: 0.0033\n",
      "Epoch 16/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 222ms/step - accuracy: 0.9899 - loss: 0.0372 - val_accuracy: 0.9900 - val_loss: 0.0457\n",
      "Epoch 17/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 226ms/step - accuracy: 0.9916 - loss: 0.0316 - val_accuracy: 0.9700 - val_loss: 0.0874\n",
      "Epoch 18/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 224ms/step - accuracy: 0.9940 - loss: 0.0207 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 19/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 223ms/step - accuracy: 0.9954 - loss: 0.0173 - val_accuracy: 0.9878 - val_loss: 0.0386\n",
      "Epoch 20/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 222ms/step - accuracy: 0.9883 - loss: 0.0417 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 21/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 223ms/step - accuracy: 0.9993 - loss: 0.0033 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 22/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 225ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9043 - val_loss: 0.2872\n",
      "Epoch 23/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 224ms/step - accuracy: 0.9864 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 24/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 226ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 1.0000 - val_loss: 6.1092e-04\n",
      "Epoch 25/999\n",
      "\u001b[1m174/174\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 226ms/step - accuracy: 0.9999 - loss: 8.6689e-04 - val_accuracy: 1.0000 - val_loss: 3.1813e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x20c7c3462a0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=999,\n",
    "    validation_split=0.01,\n",
    "    batch_size=512,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 17ms/step - accuracy: 0.9985 - loss: 0.0065\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0067401123233139515, 0.9987980723381042]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"test_model_LSTM3.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
